{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4fee3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\diego\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\diego\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2600e425",
   "metadata": {},
   "source": [
    "Get actions and states for the board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf4a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 62\n"
     ]
    }
   ],
   "source": [
    "actions = [0,1,2,3] #0 = up, 1 = right, 2 = left and 3 = down\n",
    "action_space_size = 4 #Because it has 4 actions (up, down, left, right)\n",
    "state_space_size = 62 #Because the configuration varies when Harry moves on the 9*7 board and Sirius occupies one space \n",
    "\n",
    "print(action_space_size,state_space_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "379c1990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 2., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Enviroment\n",
    "enviroment = np.zeros((7, 9))\n",
    "enviroment[1][1] = 1 #Harry \n",
    "enviroment[6][4] = 2 #Sirius\n",
    "enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67396d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 2., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialEnviroment = np.zeros((7,9)) #this will be our way to reset the enviroment.\n",
    "np.copyto(initialEnviroment, enviroment)\n",
    "initialEnviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f1b61",
   "metadata": {},
   "source": [
    "Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f79c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_episodes = 5000\n",
    "max_steps_per_episode = 100\n",
    "\n",
    "learning_rate = 0.2\n",
    "discount_rate = 0.95\n",
    "\n",
    "rewards_avg = []\n",
    "\n",
    "q_table = np.zeros((state_space_size, action_space_size))\n",
    "q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7ba94",
   "metadata": {},
   "source": [
    "Run Q-Learning algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0afbd469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myStep(action, x, y):\n",
    "    #new_state, reward, done, info = env.step(action)\n",
    "    if action == 0:\n",
    "        y+=1\n",
    "        if y >= 6:\n",
    "            y-=1\n",
    "    if action == 1:\n",
    "        x+=1\n",
    "        if x >= 8:\n",
    "            x-=1\n",
    "    if action == 2:\n",
    "        x+=1\n",
    "        if x <= 0:\n",
    "            x+=1\n",
    "    if action == 3:\n",
    "        y-=1\n",
    "        if y <= 0:\n",
    "            y+=1\n",
    "    if x == 4 and y == 6:\n",
    "        reward = 100\n",
    "        done = True\n",
    "        new_state = 1\n",
    "        info = 0\n",
    "    else:\n",
    "        reward = -1\n",
    "        done = False\n",
    "        new_state =+ 1\n",
    "        info = 0\n",
    "\n",
    "    return new_state, reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4996dd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average  0\n",
      "average  1\n",
      "average  2\n",
      "average  3\n",
      "average  4\n",
      "average  5\n",
      "average  6\n",
      "average  7\n",
      "average  8\n",
      "average  9\n",
      "average  10\n",
      "average  11\n",
      "average  12\n",
      "average  13\n",
      "average  14\n",
      "average  15\n",
      "average  16\n",
      "average  17\n",
      "average  18\n",
      "average  19\n"
     ]
    }
   ],
   "source": [
    "# This cycle is to calculate the average reward/episodes and its only purpose is to plot the nice graph below that\n",
    "# shows how the agent learn how to maximize the reward.\n",
    "x = 1\n",
    "y = 1\n",
    "for it in range(20):\n",
    "    print('average ', it)\n",
    "    rewards_all_episodes=[] #Recolects the rewards per episode\n",
    "    \n",
    "    # exporation-exploitation trade-off params\n",
    "    exploration_rate = 1 #Epsilon\n",
    "    max_exploration_rate = 1 # Epsilon max\n",
    "    min_exploration_rate = 0.01 # Epsilon min\n",
    "    exploration_decay_rate = 0.005 #Epsilon delta\n",
    "    \n",
    "    # init q table in zeros\n",
    "    q_table = np.zeros((state_space_size, action_space_size))\n",
    "\n",
    "    # iterate over the episodes\n",
    "    for episode in range(num_episodes):\n",
    "        np.copyto(enviroment, initialEnviroment) #Reset the enviroment\n",
    "        state = 0\n",
    "        done = False\n",
    "        rewards_current_episode = 0\n",
    "        \n",
    "        # iterate over the steps for an episode\n",
    "        for step in range(max_steps_per_episode):\n",
    "            # Exploration-exploitation trade-off\n",
    "            exploration_rate_threshold = random.uniform(0, 1)\n",
    "            if exploration_rate_threshold > exploration_rate:\n",
    "                action = np.argmax(q_table[state,:])\n",
    "            else:\n",
    "                action = random.choice(actions)\n",
    "\n",
    "            # Take action\n",
    "            new_state, reward, done, info = myStep(action, x, y) #Reformular funcion step\n",
    "\n",
    "            # Update Q-table for Q(s,a)\n",
    "            q_table[state, action] = q_table[state, action] * (1 - learning_rate) + \\\n",
    "                learning_rate * (reward + discount_rate * np.max(q_table[new_state, :]))\n",
    "            # transition next state\n",
    "            state = new_state\n",
    "            rewards_current_episode += reward\n",
    "\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "        # Exploration rate decay\n",
    "        exploration_rate = min_exploration_rate + \\\n",
    "        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)\n",
    "\n",
    "        rewards_all_episodes.append(rewards_current_episode)\n",
    "    rewards_avg.append(rewards_all_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c20df1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1657b44d640>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(0,num_episodes)]\n",
    "y = np.mean(rewards_avg, axis=0)\n",
    "plot.xlabel('Episodes')\n",
    "plot.ylabel('Reward')\n",
    "plot.plot(x, y,'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009645a9",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456cae65",
   "metadata": {},
   "source": [
    " Due to time neither the number of episodes nor the number of steps can be greater. More tests are indispensable.\n",
    " It was tried to run the algorithm without the library gym and some functions were replaced but more information is needed in order to know exactly how those functions work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d858d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
